---
title: "Nanostring Normalization nSolver and Nanostringr"
author: "Jenny Smith"
date: "June 2, 2017"
output:
  html_document: default
  pdf_document: default
---


```{r setup}
library(knitr)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE, fig.align='center', fig.height = 4, fig.width = 6)
knitr::opts_knit$set(root.dir = "~/Nanostring_Analysis/2017.06.05_Nanotringr_geNorm/")
```


```{r message = FALSE, warning=FALSE}
library(RColorBrewer)
library(colorspace)
library(stringr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(grid)
library(magrittr)
library(NormqPCR)
library(nanostringr)
getwd()
```


```{r}
source("~/scripts/RNAseq_Analysis/DifferentialExpn_PathwayAnalysis/Expression_Distribution_Plots_Function.r")
source("~/scripts/RNAseq_Analysis/MSLN_waterfallplots/Waterfall_Barplot_Function_2017.05.22.r")
source("~/scripts/RNAseq_Analysis/DifferentialExpn_PathwayAnalysis/merge_clinData_ExpnData_Functions.r")
source("~/scripts/RNAseq_Analysis/DifferentialExpn_PathwayAnalysis/Heatmaps_Function.r")
```


#Define Functions to be used

```{r}
#Reformat the counts that were downloaded from nSolver. 
reformatCounts <- function(counts,sampleIDmap){
  
  matchIDs <- function(reg,idMap){
  match <- idMap[grepl(reg, idMap$Reg.),]
  USI <- unique(match$USI)
  return(USI)
  }
  
  N <- ncol(counts) #number of columns
  genes <- unique(counts[,1]) %>% grep("\\w", . ,value=TRUE)  #unique gene names
  counts <- counts[-(1:2), ] #remove two rows
  
  #convert columns to numeric class
  counts[10:N] <- sapply(counts[10:N], function(x) as.numeric(as.character(x))) 
  
  #set rownames as genes
  rownames(counts) <- genes 
  
  #set column names as patient USIs
  Reg <- gsub("X[0-9].+_([0-9]{6}).+", "\\1", colnames(counts[,10:N])) %>% gsub("X[0-9].+_(BM[0-9]{4})_.+", "\\1", . )
  IDs <- sapply(Reg, matchIDs, idMap=sampleIDmap)
  
  colnames(counts)[10:N] <- IDs
  # counts <- counts[,order(colnames(counts), decreasing = TRUE)]
  
  #create phenotype vector 
  cols <- colnames(counts[,10:N])
  phenos <- ifelse(grepl(".1", cols), "Remission", cols) %>% ifelse(grepl("^BM", . ), "BM", . ) %>% ifelse(!grepl("^Rem.+|^BM", . ), "DX", . )
  names(phenos) <- cols
  
  
  list <- list(counts, phenos)
  return(list)
  
}
```

```{r}
#Reform the mergedRCC from Cassie Sather Fred Hutch email communication
#Possibly this is the output from NCounter software
reformatNanostringr <- function(mergedRCC){
  #mergedRCC is a .csv file from the individual RCCs
  
  N <- ncol(mergedRCC) #number of columns
  
  #parse the QC data (eg FOV, binding density)
  QC_data <- mergedRCC[1:14,c(1,4:N)]
  rownames(QC_data) <- QC_data[,1]
  QC_data <- t(QC_data[,-1])
  
  #convert QC data into a dataframe
  QC_data <- as.data.frame(cbind(QC_data,row.names(QC_data)))
  colnames(QC_data) <- c("Description", "Sample ID","Owner", "Sample Date","File Version","Gene RLF", "Comments", "Lane ID", "fov.count", "fov.counted","Scanner ID", "Stage Position", "binding.density", "Messages", "File.Name")
  QC_data[,c("fov.count", "fov.counted","binding.density")] <- sapply(QC_data[,c("fov.count", "fov.counted","binding.density")], function(x) as.numeric(as.character(x)))
  
  #create raw counts matrix
  counts <- mergedRCC[-(1:14), 1:N]
  names(counts)[1:3] <- c("Code.Class", "Name", "Accession")
  
  #convert columns to numeric class
  counts[4:N] <- sapply(counts[4:N], function(x) as.numeric(as.character(x))) 
  
  
  #Format the pos and negative controls with concentration in parenthases
  concentrations <- c(128,32,8,2,0.5,0.125)
  idx <- grep("^POS_|^NEG_",counts$Name)
  pos <- paste(paste(grep("POS_", counts$Name, value=TRUE), concentrations, sep="("), ")", sep="")
  neg <- paste(grep("NEG_", counts$Name, value=TRUE),"(0)", sep="")
  counts$Name[idx] <- c(pos,neg)
  
  #convert columns to numeric class
  # counts[10:N] <- sapply(counts[10:N], function(x) as.numeric(as.character(x))) 
  

  list <- list(counts, QC_data)
  return(list)
  
}
```

```{r}
reformatAdvAn <- function(df, sampleIDmap){
  
  matchIDs <- function(reg,idMap){
  match <- idMap[grepl(reg, idMap$Reg.),]
  USI <- unique(match$USI)
  return(USI)
  }
  
  fixDupIDs <- function(df){
    cols <- colnames(df)
    idx <- which(duplicated(colnames(df)))
    for ( i in 1:length(idx)){
      name <- paste(cols[idx[i]], ".1", sep="")
      cols[idx[i]] <- name
    colnames(df) <- cols
    }
    return(df)
  }

  
  Reg <- gsub("^([0-9]{6}).+", "\\1", rownames(df)) 
  IDs <- sapply(Reg, matchIDs, idMap=sampleIDmap)
  
  df.t <- as.data.frame(t(df))
  df.t <- as.data.frame(sapply(df.t, function(x) as.numeric(as.character(x))))
  rownames(df.t) <-  gsub(".mRNA", "", colnames(df))
  colnames(df.t) <- IDs
  df.t <- fixDupIDs(df.t)
  
  return(df.t) 
}
```


#Define Functions to be used
```{r}
PatientDist <- function(df, dfName){
  colors = rainbow_hcl(186)
  par(pty="m", las=2, mar=c(5,4,5,2))
  boxplot(df, col=colors,cex.axis=0.45,outline=FALSE, ylim=c(0,17))
  
  title <- paste("Distribution of Gene Expression for TARGET AML \n ", dfName, sep = " ")
  title(main = title, line = 2.5, cex.main = 0.8, ylab = "Log2 Counts", xlab="Patient", cex.lab=0.75)
}
```

```{r}
geneDist <- function(df, dfName){
  colors = rainbow_hcl(50)
  par(pty="m", las=2, mar=c(5,4,5,2))
  
  df <- as.data.frame(t(df))
  
  df1 <- df[,1:50]
  df2 <- df[,51:100]
  df3 <- df[,101:150]
  df4 <- df[,151:200]
  df5 <- df[,201:234]
  
  for (i in 1:5){
    df <- get(paste("df", i, sep=""))
    boxplot(df, col=colors,cex.axis=0.65)
    title <- paste("Distribution of Gene Expression in TARGET AML:", dfName, sep = " ")
    title(main = title, line = 3.0, cex.main = 0.8, ylab = "Log2 Counts", xlab="Gene Name", cex.lab=0.75)
  }
}
```




#Read in the annotation data

```{r}
anno <- read.csv("~/Nanostring_Analysis/2017.05.04_DataExploration/NanostringAnnotations_04May2017.csv", stringsAsFactors = FALSE)
anno$DX_Induction <- ifelse(anno$DX_Induction == "Induction", "EOI", anno$DX_Induction )

clinData <- read.csv("~/reference_mapping-files/New_stratification_outcomes_FORMATTED_updated_2017.03.28.csv", stringsAsFactors = FALSE, row.names = 1)
```

```{r}
head(anno)
```

```{r}
dim(anno)
```


#Read in the raw counts

```{r}
raw <- read.csv("~/Nanostring_Analysis/2017.06.05_Nanotringr_geNorm/AML_EXPR_C5117_DX_Induction_BM_Raw_Counts.csv", stringsAsFactors = FALSE)

mergedRCC <-  read.csv("~/Nanostring_Analysis/2017.06.05_Nanotringr_geNorm/AML_EXPR_C5117_170427_01-16.csv", stringsAsFactors = FALSE)
```

```{r}
head(raw[,1:5])
```

```{r}
head(mergedRCC[,1:5])
```

##Format the raw counts

```{r}
reformatted <- reformatNanostringr(mergedRCC)
```

```{r}
raw <- reformatted[[1]]

raw[1:10,1:5]
```

```{r}
unique(raw$Code.Class)
# str(raw)
# sapply(raw, is.factor)
```

```{r}
HKs <- subset(raw, Code.Class == "Housekeeping" )
genes <- subset(raw, Code.Class == "Endogenous")
ERCC <- subset(raw, grepl("Positive|Negative", raw$Code.Class))
```


```{r}
QC <- reformatted[[2]]
head(QC)
```



#nSolver Default Settings 

```{r}
nSolver <- read.csv("AA_geomeanNorm_withBackgroundSub 2017-06-08 17-51/results/Normalization/ALL_normalized log2 data.csv", stringsAsFactors = FALSE, row.names = 1)

head(nSolver[,1:5])
```

```{r}
nSolver.t <- reformatAdvAn(nSolver, anno)

head(nSolver.t)
```


```{r}
nSolver.cts <- sapply(nSolver.t, function(x) 2^x)
rownames(nSolver.cts) <- rownames(nSolver.t)

head(nSolver.cts[,1:5])
```

```{r}
# save(nSolver.cts,file= "~/Nanostring_Analysis/2017.06.08_NormalizationMethods/nSolver.test.RData")
```
This is to check the results of the two advanced analysis methods are not due to 1) dx and eoi being switched 2) Advanced Analysis is modifyign the data in a way I havent noticed yet 

However, the results of this indicate that there is not an error in eoi/dx switching, or AA modifications bc the results are identical whethe I import nSolver.cts, or the data directly from the H:\Nanostring_Analysis\2017.05.04_DataExploration folder. 

see TARGET_AML_Nanostring_NormalizationComparison.Rmd

#Advanced Analysis 

#Advanced Analysis Normalized Counts: geNorm only
##QC 

"Datasets with exclusively low raw counts (e.g., counts < 100) may arise from experimental failure or low input. The detected3/undetected calls links to a .csv file stating whether each probe is above background, with 0/1 indicating below/above background. If the user has not specified a detection threshold, probes for mRNA are called detected if they have more than double the counts of the median negative control."

Minimum Count Threshold
"Removes probes from the analysis based on a specified threshold count value and observation frequency across all samples. Probes that fall below the threshold at a frequency greater than the specified observation frequency will be removed from the analysis. To change our defaults, first de-select the "auto" checkbox.

Threshold count value: (min = 0, max = 100)
Observation frequency: (min = 0, max = 1)"

My setting was to have a minium count of 20 with an observation frequency of 75%. 

```{r}
detected <- read.csv("AMLvsBM 2017-06-07 17-45/results/QC/above background detection call.csv", row.names = 1, stringsAsFactors = FALSE)

dim(detected) #only AML and BM Samples
```

```{r}
head(detected[,1:5])
detected <- detected[-1, ]
```
```{r}
USI <- subset(anno, grepl("BM|EOI|DX", anno$DX_Induction))
dim(USI)           
```

```{r}
detected.t <- as.data.frame(t(detected))
detected.t <- as.data.frame(sapply(detected.t, function(x) as.numeric(as.character(x)))) #WHY does this become a matrix
rownames(detected.t) <- colnames(detected)
colnames(detected.t) <- USI$USI
detected.t <- fixDupIDs(detected.t, type="colnames")

head(detected.t[,1:5])
```

```{r}
# write.csv(detected.t, "TARGET_AML_NanostringPanel_AdvancedAnalysis_genesAboveBackground.csv")
```

```{r}
percentDetected <- sapply(detected.t, function(x) sum(x)/length(x) * 100)
names <- names(percentDetected)
group <- gsub("[0-9]{6}\\-([A-Z0-9])", "\\1", names) %>% gsub("(BM)[0-9]{4}", "\\1", .) %>% ifelse(grepl("DX|BM", . ), ., "EOI")
percentDetected <- data.frame(group, percentDetected)
```


```{r}
colors <- rainbow(3, s=0.5,v=0.85, start=0.5, end=0.8)

# pdf(file="TARGET_AML_Nanostring_AdvancedAnalysis_percentDetected.pdf", height = 5, width = 5)
boxplot(percentDetected$percentDetected ~ percentDetected$group, ylab="% Genes Detected", main="Percent of Genes Detected Above Background", col=colors)
stripchart(percentDetected$percentDetected ~ percentDetected$group, 
           vertical = TRUE, method = "jitter",  
           pch = 21, cex = 0.4 , col ="black", 
           bg=c(rep(colors[1], 18), rep(colors[2], 84),rep(colors[3],84)), 
           add = TRUE) 
# dev.off()
```

##Normalization

Normalization with geNorm with dynamically chosen HKs. 

```{r}
geNorm <- read.csv("AMLvsBM 2017-06-07 17-45/results/Normalization/ALL_normalized log2 data.csv", stringsAsFactors = FALSE,
                   row.names = 1)
```

```{r}
head(geNorm[,1:5])
```

```{r}
dim(geNorm)
```

```{r}
colnames(geNorm) <- gsub(".mRNA", "", colnames(geNorm))
geNorm.t <- as.data.frame(t(geNorm))
geNorm.t <- as.data.frame(sapply(geNorm.t, function(x) as.numeric(as.character(x))))
rownames(geNorm.t) <- colnames(geNorm)
colnames(geNorm.t) <- USI$USI
geNorm.t <-fixDupIDs(geNorm.t, type="colnames")


head(geNorm.t[,1:5])
```

```{r}
geNorm.cts <- sapply(geNorm.t, function(x) 2^x)
rownames(geNorm.cts) <- rownames(geNorm.t)
head(geNorm.cts[,1:5])
```


```{r}
# write.csv(geNorm.cts, file="TARGET_AML_NanostringPanel_AdvancedAnalysis_geNorm_counts.csv")
# save(geNorm.cts, file="TARGET_AML_NanostringPanel_AdvancedAnalysis_geNorm_counts.RData")
```


#Advanced Analysis: HK and POS ERCC Normalized counts

Added after the results of the heirachal clustering showed discordant results.

This had HK normalization based on the same dynamically chosen HKs
```{r}
opt.geNorm <-  read.csv("AA_geomeanNorm_noBackgroundSub 2017-06-08 18-05/results/Normalization/ALL_normalized log2 data.csv", stringsAsFactors = FALSE, row.names = 1)
dim(opt.geNorm)
```

```{r}
head(opt.geNorm[,1:5])
```


```{r}
opt.geNorm.t <- reformatAdvAn(opt.geNorm, anno)

head(opt.geNorm.t[,1:5])
```

```{r}
opt.geNorm.cts <- sapply(opt.geNorm.t, function(x) 2^x)
rownames(opt.geNorm.cts) <- rownames(opt.geNorm.t)

head(opt.geNorm.cts[,1:5])
```


```{r}
# write.csv(opt.geNorm.cts, file= "TARGET_AML_NanostringPanel_geNormPosNorm_counts.csv")
# save(opt.geNorm.cts, file="TARGET_AML_NanostringPanel_geNormPosNorm_counts.RData")
```

Results: Absolutely no difference. they are identical results. the thresholding does not affect the normalizatin results either. Download the normalized counts from AA folders or from export button in the 

#Advanced Analysis: Manually Select HKs

Skipped the geNorm alg. and instead used all 10 HKs in the codeset
No backgound,not pos control normalization. 
thresh = 20 counts, 75% obs freq. 

```{r}
selectHK <- read.csv("AA_ManuallySelectHKs 2017-06-08 21-50/results/Normalization/ALL_normalized log2 data.csv", row.names = 1, stringsAsFactors = FALSE) 

head(selectHK)
```

```{r}
selectHK.t <- reformatAdvAn(selectHK, anno)

head(selectHK.t)
```

```{r}
selectHK.cts <- sapply(selectHK.t, function(x) 2^x)
rownames(selectHK.cts) <- rownames(selectHK.t)

head(selectHK.cts[,1:5])
```

```{r}
# save(selectHK.cts,file= "TARGET_AML_NanostringPanel_manuallySelectHKsNorm_counts.RData")
```


#Replication of Nanostring AA normalization methods. TO DO!!

Advanced Analysis Manual. 
"As both sample input and reaction efficiency are expected to affect all probes uniformly5, normalization for run-to-run variability is done by dividing counts within a lane by the geometric mean of the reference/normalizer probes from the same lane (i.e., all probes/count levels within a lane are adjusted by the same factor) 6."

```{r}
#From Nanostring nSolver normalize.r (directly copied)
normalize.given.HKs = function(raw,HKdata,HKs)
{   
  # use only the selected HKs:
  HKdata.selected = HKdata[,is.element(dimnames(HKdata)[[2]],HKs)]
  # get mean of HKs
  HKmeans = apply(HKdata.selected,1,mean)
  # apply norm factors:
  norm.factors = HKmeans-mean(HKmeans)
  normalized = raw-norm.factors
  HKnormalized = HKdata-norm.factors
  out = list(normalized=normalized,HKnormalized=HKnormalized,norm.factors=norm.factors)
  return(out)
}
```

    if(choose.method=="geNorm")
    {
      minNrHKs = 2
      # run geNorm:
      temp = selectHKs(HKdata,method="geNorm",minNrHKs=minNrHKs,log=TRUE,Symbols = dimnames(HKdata)[[2]],trace=FALSE)
      ## select top number of genes:
      # if you decided beforehand how many to take:
      if(!auto.HKs)
      {
        HKs = as.vector(temp$ranking)[1:n.HKs]
      }
      # if you want to choose the top housekeepers dynamically:
      nselect=n.HKs
      if(auto.HKs)
      {
        nselect = dim(HKdata)[2]-(1:length(temp$variation))[temp$variation==min(temp$variation)]+1
        # require at least 6 HKs:
        nselect = max(nselect,6)
        HKs = as.vector(temp$ranking)[1:nselect] 
      }
      

#Drop Low Counts
Need to look at source code for the thresholding so that 
```{r}

```


#Identify HK genes



The biggest question is what are the codeset.HKs that is defined in the code? for dynamic HK gene choice, it appears to be all the genes (including designated HKs) except ERCCs. The other option is to specifiy the HK genes? 

nSovlver software source code only notes that codeset.HKs variable is the probe annotations. 

```{r}
# temp = selectHKs(HKdata,method="geNorm",minNrHKs=minNrHKs,log=TRUE,Symbols = dimnames(HKdata)[[2]],trace=FALSE)
HKdata <- raw[]
```

Nsolver Adavnced Analysis manual
"Normalization uses the popular geNorm algorithm (Vandesompele, 2002) to identify an optimal subset of probes for normalization. While expression of a good housekeeping gene may vary between samples in non-normalized data, the ratio between two good housekeepers should be very stable. geNorm relies on this theory, iteratively removing candidate housekeepers with the least stable expression relative to other candidates. The user may also specify the desired number of normalization probes."



#Nanotringr 


##Format the raw counts

```{r}
# https://github.com/OVCARE/nanostringr/blob/master/R/NanoStringQC.R
NanoStringQC_edit <- function(raw, exp, detect = 50, sn.in = 50) {

  # # Run a bunch of checks to make sure the data is in the right order
  # assertthat::assert_that(check_colnames(raw))  # Checks format of raw counts
  # assertthat::assert_that(check_genes(raw))  # Checks that HK genes are specified
  # assertthat::assert_that(ncol(raw) == nrow(exp) + 3)
  # cn <- colnames(raw[, -(1:3)])
  # if (all(grepl("[[:digit:]]", substring(cn, 1, 1)))) {
  #   assertthat::assert_that(all(substring(cn, 2) == exp$File.Name))
  # } else if (all(grepl("[[:alpha:]]", substring(cn, 1, 1)))) {
  #   assertthat::assert_that(all(substring(cn, 1) == exp$File.Name))
  # }

  # sn.in <- sn
  genes <- raw$Name
  rownames(raw) <- genes
  HKgenes <- genes[raw$Code.Class == "Housekeeping"]
  PCgenes <- genes[raw$Code.Class == "Positive"]
  NCgenes <- genes[raw$Code.Class == "Negative"]
  Hybgenes <- genes[raw$Code.Class != "Endogenous"]
  if (!all(grepl("[[:digit:]]", PCgenes))) {
    stop("Positive controls must have concentrations in brackets: ex POS_A(128)")
  }
  
  #initiaze variables
  PCconc <- as.numeric(sub("\\).*", "", sub(".*\\(", "", PCgenes)))
  flag.levs <- c("Failed", "Passed")
  linPC <- linFlag <- fov.counted <- fov.count <- perFOV <- ncgMean <-
    ncgSD <- llod <- lod <- gd <- averageHK <- binding.density <- pergd <-
    spcFlag <- normFlag <- imagingFlag <- linFlag <- rn <- NULL

  # raw counts for pos A-E against concentrations (128-0.125fM from lit)
  #same as for nSolver default. 
  linPC = round(apply(raw[PCgenes, -(1:3)], 2, function(x) summary(lm(x ~ PCconc))$r.squared), 3) #
  
  linFlag = factor(ifelse(linPC < 0.95 | is.na(linPC), "Failed", "Passed"), flag.levs)
  
  perFOV = (exp$fov.counted / exp$fov.count) * 100
  
  #same a default nSolver 75% cutoff for flag
  imagingFlag = factor(ifelse(perFOV < 75, "Failed", "Passed"), flag.levs)

  ncgMean = apply(raw[NCgenes, -(1:3)], 2, mean) #ncg = negative control geometric mean
   
  ncgSD = apply(raw[NCgenes, -(1:3)], 2, sd) 
  
  #limit of detection. Same at default
  lod = ncgMean + 2 * ncgSD

  llod = ncgMean - 2 * ncgSD
  
  #limit of detection. Same as default. 
  #positive control at 0.5fM must be greater than the two sd above ncg mean
  spcFlag = factor(ifelse(t(as.vector(raw["POS_E(0.5)", -(1:3)]) < llod | ncgMean == 0), "Failed", "Passed"), flag.levs)
  
  #genes detectable. sum logical vectors == counting them
  gd = apply(raw[!(rownames(raw) %in% Hybgenes), -(1:3)] > lod, 2, sum)
  #percent of genes detectable
  pergd = (gd / nrow(raw[!(rownames(raw) %in% Hybgenes), -(1:3)])) * 100
 
  #https://stackoverflow.com/questions/2602583/geometric-mean-is-there-a-built-in
  # averageHK = exp(apply(log2(raw[HKgenes, -(1:3)]), 2, mean)) #Actually check on this. 
  averageHK = exp(apply(log(raw[HKgenes, -(1:3)]), 2, mean)) 
  
  #Signal to Noise, where noise is limit of detection. 
  sn = ifelse(lod < 0.001, 0, averageHK / lod)
  
  #default binding density setting from nSolver
  bdFlag = factor(ifelse(exp$binding.density < 0.05 | exp$binding.density > 2.25, "Failed", "Passed"), flag.levs)

  # normFlag = factor(ifelse(sn < sn.in | pergd < detect,"Failed", "Passed"), flag.levs)

  normFlag = factor(ifelse(sn < sn.in,"Failed", "Passed"), flag.levs)
  
  
  QCFlag = factor(ifelse(as.vector(spcFlag == "Failed" | imagingFlag == "Failed" | linFlag == "Failed"),"Failed", "Passed"))
  
  QC_Metrics <- data.frame(linPC, linFlag,perFOV,
                                    imagingFlag, ncgMean, ncgSD, lod, llod, spcFlag,
                                    gd, pergd,averageHK,sn,bdFlag,normFlag,QCFlag)
  names(QC_Metrics) <- c("linPC", "linFlag","perFOV",
                                    "imagingFlag", "ncgMean", "ncgSD", "lod", "llod", "spcFlag",
                                    "gd", "pergd","averageHK","sn","bdFlag","normFlag","QCFlag")
  # print(c(sn, sn.in))
  # t <- data.frame(lod, gd, pergd, sn, normFlag)
  return(QC_Metrics)
}
```

The  first edit was to remove mutate() because this caused an error for me. That was likely due to numeric values being classified as factors, but that was fixed. Second, perGD will not  be used since we already know that gene expression for these are highly variable.
third, the averageHK metric was off it appears. It results in VERY high sn ratios across the board. After editing it to the geometric mean, the range of sn changed from over 1-600,000 to a more moderate and expected range of 1-500. 

```{r}
NanoStringQC <- NanoStringQC_edit(raw, QC)
```

```{r}
head(NanoStringQC[,1:5])
```


```{r}
range(NanoStringQC$linPC)
min(NanoStringQC$)
```


#Merge the QC adn annotations
```{r}
rownames(anno) <- rownames(NanoStringQC)
# Reduce(function(x, y) merge(x, y, all=TRUE), list(df1, df2, df3))
AllQC <- NULL
AllQC <- data.frame(merge(NanoStringQC, QC, by.x=0, by.y= 0), row.names = "Row.names")
AllQC <- data.frame(merge(anno, AllQC, by.x=0, by.y=0), row.names = "Row.names")
```

```{r}
dim(AllQC)
```


```{r}
# write.csv(AllQC, file="TARGET_AML_NanostringPanel_nanostringrQC.csv")
# save(AllQC, file="TARGET_AML_NanostringPanel_nanostringrQC.RData")
```

#QC Plots

```{r}
AML_BM_QC <- AllQC[grepl("EOI|DX|BM", AllQC$DX_Induction), ]
```

```{r}
boxplot(AllQC$perFOV ~ AllQC$DX_Induction, ylab = "% FOV", 
        main = "Percent FOV by Group", pch = 20, ylim=c(90,100), 
        col=rainbow_hcl(5))
```


```{r}
tapply(AML_BM_QC$perFOV, INDEX = list(AML_BM_QC$DX_Induction), FUN=median)
```

```{r}
tapply(AML_BM_QC$pergd, INDEX=list(AML_BM_QC$DX_Induction), FUN=median)
```

```{r}
tapply(AML_BM_QC$pergd, INDEX=list(AML_BM_QC$DX_Induction), FUN=range)
```



```{r fig.width=10, fig.height=10}
colors <- rainbow(3, s=0.5,v=0.85, start=0.5, end=0.8)
options(scipen = 999)

# pdf(file="TARGET_AML_NanostringPanel_NanostringrQC.pdf", height = 8, width = 11)
par(mfrow=c(2,3), cex.axis=1.5, cex.main=2, cex.lab=1.5, mar=c(5, 5, 4, 2))
boxplot(AML_BM_QC$perFOV ~ AML_BM_QC$DX_Induction, ylab = "% FOV", 
        main = "Percent FOV", pch = 20, ylim=c(90,100), 
        col=rainbow(3, s=0.5,v=0.85, start=0.5, end=0.8))
boxplot(AML_BM_QC$binding.density ~ AML_BM_QC$DX_Induction, 
        ylab = "Binding Density", main = "Binding Density of Lane", 
        col=colors)
boxplot(AML_BM_QC$linPC ~ AML_BM_QC$DX_Induction, 
        ylab = expression(R ^ 2), main = "Linearity of Positive Controls", 
        col=colors, ylim=c(0,1))


boxplot(AML_BM_QC$averageHK ~ AML_BM_QC$DX_Induction, 
        ylab = "Geometric mean Expression", main = "Geometric mean Expression of \n Housekeeping Genes", 
        col=colors)
boxplot(AML_BM_QC$lod ~ AML_BM_QC$DX_Induction, 
        ylab = "Limit of Detection", main = "Limit of Detection for Samples", 
        col=colors)
boxplot(AML_BM_QC$pergd ~ AML_BM_QC$DX_Induction, 
        ylab ="% Genes Detected", main = "Percent of Genes Detected \n Above Background", 
        col=colors)
stripchart(AML_BM_QC$pergd ~ AML_BM_QC$DX_Induction, 
           vertical = TRUE, method = "jitter",  
           pch = 21, cex = 0.4 , col ="black", 
           bg=c(rep(colors[1], 18), rep(colors[2], 84),rep(colors[3],84)), 
           add = TRUE) 
# dev.off()
```


```{r}
range(AML_BM_QC$sn)
range(log2(AML_BM_QC$sn+1))
```

Question: Why choose a specific sn cutoff? 100 in the paper, 150 by defual in nanostringQC. 

But anything far above LOD should be good to go. so keep all genes based on these results. 

The original code from nanostringr had an error in the geometric mean calculation which lead to an huuuge sn ratio that was seen. 

Now there are 

```{r}
hist(AML_BM_QC$sn, breaks=seq(0,500, by=10), xlim=c(0,500), main="Distribution of Signal-to-Noise")
abline(v=50, col="red") #100 as cutoff
# abline(v=10, col="blue") #1024 as sn cutoff
```

```{r}
# log2sn <- log2(AML_BM_QC$sn+1)
# log2sn <- data.frame(AML_BM_QC$DX_Induction, log2sn)
# rownames(log2sn) <- rownames(AML_BM_QC)
sn <- data.frame(AML_BM_QC$DX_Induction, AML_BM_QC$sn)
rownames(sn) <- rownames(AML_BM_QC)
```

```{r fig.width=7}
colorsAlpha <- rainbow(3, s=0.5,v=0.85, start=0.5, end=0.8, alpha = 0.65)

# pdf(file="TARGET_AML_NanostringPanel_snMetric.pdf", height = 5, width=5)
par(mfrow=c(1,1), cex.axis=1.5, cex.main=1.5, cex.lab=1.5, mar=c(5, 5, 4, 2))

hist(sn[which(sn$AML_BM_QC.DX_Induction == "DX"), ]$AML_BM_QC.sn, breaks=seq(0,500, by=10), xlim=c(0,500),
     ylim=c(0,20), col=colorsAlpha[2], xlab="", main="Distribution of Signal-to-Noise Metrics")

hist(sn[which(sn$AML_BM_QC.DX_Induction == "EOI"), ]$AML_BM_QC.sn,breaks=seq(0,500, by=10), xlim=c(0,500),
     ylim=c(0,20), add=T, col=colorsAlpha[3], xlab="")

hist(sn[which(sn$AML_BM_QC.DX_Induction == "BM"), ]$AML_BM_QC.sn, breaks=seq(0,500, by=10), xlim=c(0,500),
     ylim=c(0,20), add=T,col=colors[1], xlab="")
# abline(v=100, col="red") #100 as cutoff
legend(x=350, y=20, legend = c("BM", "DX", "EOI"), col=colors, pch=15)
# abline(v=10, col="blue") #1024 as sn cutoff
# dev.off()
```


#Normalization 

```{r}
# https://github.com/OVCARE/nanostringr/blob/master/R/HKnorm.R
HKnorm <- function(raw.data, is.logged = FALSE, corr = 0.0001) {
  # assertthat::assert_that(check_colnames(raw.data))
  # assertthat::assert_that(check_genes(raw.data))
  rawdat <- raw.data[, -(1:3)]
  rownames(rawdat) <- raw.data$Name
  hks <- raw.data$Code.Class == "Housekeeping"
  refs <- raw.data$Code.Class != "Endogenous"
  if (is.logged == FALSE) {
    rawdat <- rawdat + corr
    logHK <- apply(log2(rawdat[hks, ]), 2, mean)
    logXpr <- log2(rawdat[!refs, ])
  } else {
    logHK <- apply(rawdat[hks, ], 2, mean)
    logXpr <- rawdat[!refs, ]
  }
  norm <- t(apply(logXpr, 1, function(x) x - logHK)) #substracting the log2 mean from log2 genes counts
  normdat <- cbind(raw.data[!refs, 1:3], norm)
  rownames(normdat) <- raw.data$Name[!refs]
  
  list <- list(logHK, logXpr,normdat)
  names(list) <- c("logHK", "logExpn", "normdat")
  return(list)
}
```

#Example data from the paper 
```{r}
hld <- hld.r[, !colnames(hld.r) %in% c("HL1_18", "HL2_18")]
```

```{r}
dim(hld)
```

```{r}
hld.n <- HKnorm(hld)
```

```{r}
#log2 + 0.0001 expression of endogenous genes
head(hld.n$logExpn[,1:2])
```

```{r}
#log2 HK genes vector
head(hld.n$logHK)
```


```{r}
#Why subtract from rows? 
# norm <- t(apply(logXpr, 1, function(x) x - logHK))
# hld.n$logExpn[,1]

#each sample has the log2 mean of the HK genes subtracted from it. 
#yes, rows makes sense. HL1_1  minus log2 mean HK for HL1_1 (9.59 - 12.87), then HL1_10 minus mean HK HL1_10
# test <- apply(hld.n$logExpn[1:10,1:5], 1, function(x) print(x))
```

```{r}
head(hld.n$normdat[1:10,4:8])
```

Conclusion: There are TONS of negative numbers! thus very very small ratios

```{r}
range(hld.n$normdat["A2M",4:75]) #example
```

## Complete with out own data
```{r}
#check out raw HK numbers
#very high counts and large dynamic range
HK <- raw[raw$Code.Class == "Housekeeping", ]
head(HK[,1:5])
```

```{r}
head(raw[raw$Code.Class == "Endogenous", 4])
```

None failed the QC flags, so ok to proceed
```{r}
any(AML_BM_QC$QCFlag == "Failed")
```

```{r}
norm <- HKnorm(raw, is.logged = FALSE) 
```


```{r}
head(norm$logHK[1:10])
```

```{r}
head(norm$logExpn[,1:10])
```

```{r}
head(norm$normdat[,4:10])
```


```{r}
# norm <- get(load("TARGET_AML_NanostringPanel_nanostringr_HKnormResults.RData"))
```

```{r}
hknorm.cts <- sapply(norm$normdat[,4:195], function(x) 2^x)
rownames(hknorm.cts) <- rownames(norm$normdat)
head(hknorm.cts[,1:5])
```

```{r}
# write.csv(norm$normdat, file="TARGET_AML_NanostringPanel_nanostringr_geomeanNorm.csv")
# write.csv(norm.cts, file="TARGET_AML_NanostringPanel_nanostringr_HKnorm_counts.csv")
# save(norm, file="TARGET_AML_NanostringPanel_nanostringr_HKnormResults.RData")
# save(hknorm.cts, file="TARGET_AML_NanostringPanel_nanostringr_HKnorm_counts.RData")

```


###Notes

```{r}
library(psych)

# geoMean
g1 <- geometric.mean(HK[,4:ncol(HK)])
g2 <- sapply(HK[,4:ncol(HK)], geomMean)
head(cbind(g1, g2,AllQC$averageHK))
```

